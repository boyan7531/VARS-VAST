#!/usr/bin/env python3
"""
MVFouls Training Script with Proper Class Imbalance Handling

This script addresses the severe class imbalance in MVFouls dataset by:
1. Computing proper class weights for each task
2. Using focal loss with effective number weighting
3. Implementing task-specific loss strategies
4. Monitoring per-class metrics during training
"""

import argparse
import json
import logging
import sys
from pathlib import Path
from typing import Dict, Any, Optional

import torch
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter

# Add project root to path
sys.path.append(str(Path(__file__).parent))

from model.mvfouls_model import MVFoulsModel, build_multi_task_model, build_single_task_model
from dataset import MVFoulsDataset
from transforms import get_video_transforms
from training_utils import MultiTaskTrainer
from utils import (
    get_task_metadata, 
    compute_class_weights, 
    get_recommended_loss_config,
    get_task_class_weights,
    analyze_class_distribution
)


def setup_logging(level: str = 'INFO'):
    """Setup logging configuration."""
    logging.basicConfig(
        level=getattr(logging, level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)


def analyze_dataset_imbalance(dataset: MVFoulsDataset) -> Dict[str, Dict]:
    """Analyze class imbalance in the dataset and recommend solutions."""
    logger = logging.getLogger(__name__)
    
    logger.info("ðŸ” Analyzing dataset class imbalance...")
    
    # Get dataset statistics
    stats = dataset.get_task_statistics()
    
    recommendations = {}
    
    for task_name, task_stats in stats.items():
        class_counts = task_stats['class_counts']
        total_samples = sum(class_counts)
        
        if total_samples == 0:
            continue
            
        # Calculate imbalance ratio
        max_count = max(class_counts)
        min_count = min([c for c in class_counts if c > 0]) if any(c > 0 for c in class_counts) else 1
        imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')
        
        # Get recommendations
        dummy_labels = []
        for class_idx, count in enumerate(class_counts):
            dummy_labels.extend([class_idx] * count)
        
        config = get_recommended_loss_config(dummy_labels)
        
        recommendations[task_name] = {
            'imbalance_ratio': imbalance_ratio,
            'total_samples': total_samples,
            'class_counts': class_counts,
            'class_names': task_stats['class_names'],
            'recommended_config': config,
            'severity': 'SEVERE' if imbalance_ratio > 10 else 'MODERATE' if imbalance_ratio > 3 else 'MILD'
        }
        
        logger.info(f"ðŸ“Š {task_name}:")
        logger.info(f"   Imbalance ratio: {imbalance_ratio:.1f}:1 ({recommendations[task_name]['severity']})")
        logger.info(f"   Recommendation: {config['recommendation']}")
        
        # Show class distribution
        for class_idx, (class_name, count) in enumerate(zip(task_stats['class_names'], class_counts)):
            percentage = (count / total_samples) * 100 if total_samples > 0 else 0
            logger.info(f"     {class_name}: {count} ({percentage:.1f}%)")
    
    return recommendations


def create_balanced_model(
    multi_task: bool = True,
    imbalance_analysis: Optional[Dict] = None,
    **model_kwargs
) -> MVFoulsModel:
    """Create a model with proper class imbalance handling."""
    logger = logging.getLogger(__name__)
    
    if multi_task:
        # Get task metadata
        metadata = get_task_metadata()
        task_names = metadata['task_names']
        
        # Prepare task-specific configurations
        task_weights = {}
        loss_types_per_task = []
        
        for task_name in task_names:
            if imbalance_analysis and task_name in imbalance_analysis:
                analysis = imbalance_analysis[task_name]
                config = analysis['recommended_config']
                
                # Use recommended class weights
                if config['class_weights'] is not None:
                    task_weights[task_name] = config['class_weights']
                
                # Use recommended loss type
                loss_types_per_task.append(config['loss_type'])
                
                logger.info(f"ðŸŽ¯ {task_name}: {config['loss_type']} loss, "
                          f"weights: {config['class_weights'] is not None}")
            else:
                # Default to focal loss for unknown tasks
                loss_types_per_task.append('focal')
        
        # Create multi-task model with balanced configuration
        model = build_multi_task_model(
            backbone_pretrained=True,
            backbone_freeze_mode='gradual',
            loss_types_per_task=loss_types_per_task,
            class_weights=task_weights,
            **model_kwargs
        )
        
    else:
        # Single-task model with class weights
        class_weights = None
        if imbalance_analysis and 'offence' in imbalance_analysis:
            config = imbalance_analysis['offence']['recommended_config']
            class_weights = config['class_weights']
            loss_type = config['loss_type']
        else:
            loss_type = 'focal'
        
        # Filter out conflicting kwargs
        filtered_kwargs = {k: v for k, v in model_kwargs.items() 
                          if k not in ['head_loss_type', 'head_label_smoothing']}
        
        model = build_single_task_model(
            num_classes=2,
            backbone_pretrained=True,
            backbone_freeze_mode='gradual',
            head_loss_type=loss_type,
            class_weights=class_weights,
            **filtered_kwargs
        )
    
    return model


def main():
    """Main training function with class imbalance handling."""
    parser = argparse.ArgumentParser(description='Train MVFouls Model with Class Balance')
    
    # Data arguments
    parser.add_argument('--train-dir', type=str, required=True, help='Training data directory')
    parser.add_argument('--val-dir', type=str, required=True, help='Validation data directory')
    parser.add_argument('--train-annotations', type=str, required=True, help='Training annotations file')
    parser.add_argument('--val-annotations', type=str, required=True, help='Validation annotations file')
    
    # Model arguments
    parser.add_argument('--multi-task', action='store_true', help='Use multi-task learning')
    parser.add_argument('--num-classes', type=int, default=2, help='Number of classes (single-task only)')
    
    # Training arguments
    parser.add_argument('--epochs', type=int, default=20, help='Number of epochs')
    parser.add_argument('--batch-size', type=int, default=8, help='Batch size')
    parser.add_argument('--lr', type=float, default=1e-4, help='Learning rate')
    parser.add_argument('--weight-decay', type=float, default=1e-4, help='Weight decay')
    parser.add_argument('--freeze-mode', type=str, default='gradual', help='Backbone freeze mode')
    
    # Balance-specific arguments
    parser.add_argument('--analyze-only', action='store_true', help='Only analyze imbalance, dont train')
    parser.add_argument('--force-weights', type=str, choices=['balanced', 'effective', 'focal'], 
                       help='Force specific weighting method')
    parser.add_argument('--focal-gamma', type=float, default=2.0, help='Focal loss gamma parameter')
    
    # Other arguments
    parser.add_argument('--output-dir', type=str, default='./outputs_balanced', help='Output directory')
    parser.add_argument('--device', type=str, default='auto', help='Device to use')
    parser.add_argument('--verbose', action='store_true', help='Verbose logging')
    
    args = parser.parse_args()
    
    # Setup logging
    log_level = 'DEBUG' if args.verbose else 'INFO'
    logger = setup_logging(log_level)
    
    # Setup device
    if args.device == 'auto':
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(args.device)
    
    logger.info(f"ðŸš€ Starting balanced MVFouls training")
    logger.info(f"Device: {device}")
    logger.info(f"Multi-task: {args.multi_task}")
    
    try:
        # Create transforms
        transforms = get_video_transforms(image_size=224, augment_train=True)
        
        # Create datasets
        logger.info("ðŸ“‚ Creating datasets...")
        
        # Extract root directory
        root_dir = str(Path(args.train_dir).parent)
        train_split = Path(args.train_dir).name.replace('_720p', '')
        val_split = Path(args.val_dir).name.replace('_720p', '')
        
        train_dataset = MVFoulsDataset(
            root_dir=root_dir,
            split=train_split,
            transform=transforms['train'],
            load_annotations=True,
            num_frames=32
        )
        
        val_dataset = MVFoulsDataset(
            root_dir=root_dir,
            split=val_split,
            transform=transforms['val'],
            load_annotations=True,
            num_frames=32
        )
        
        logger.info(f"ðŸ“Š Dataset sizes: {len(train_dataset)} train, {len(val_dataset)} val")
        
        # Analyze class imbalance
        logger.info("ðŸ” Analyzing class imbalance...")
        imbalance_analysis = analyze_dataset_imbalance(train_dataset)
        
        if args.analyze_only:
            logger.info("âœ… Analysis complete. Exiting (--analyze-only specified).")
            return
        
        # Create balanced model
        logger.info("ðŸ—ï¸ Creating balanced model...")
        model = create_balanced_model(
            multi_task=args.multi_task,
            imbalance_analysis=imbalance_analysis
        )
        
        # Create dataloaders
        train_loader = DataLoader(
            train_dataset,
            batch_size=args.batch_size,
            shuffle=True,
            num_workers=4,
            pin_memory=True,
            drop_last=True
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=args.batch_size,
            shuffle=False,
            num_workers=4,
            pin_memory=True,
            drop_last=False
        )
        
        # Create optimizer
        optimizer = optim.AdamW(
            model.parameters(),
            lr=args.lr,
            weight_decay=args.weight_decay
        )
        
        # Create scheduler
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=args.epochs
        )
        
        # Create trainer
        trainer = MultiTaskTrainer(
            model=model,
            optimizer=optimizer,
            device=device,
            log_interval=50,
            eval_interval=1,
            gradient_accumulation_steps=1,
            max_grad_norm=1.0
        )
        
        # Setup output directory
        output_dir = Path(args.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Save configuration
        config = {
            'args': vars(args),
            'imbalance_analysis': imbalance_analysis,
            'model_config': model.config
        }
        
        with open(output_dir / 'config.json', 'w') as f:
            json.dump(config, f, indent=2, default=str)
        
        # Setup tensorboard
        writer = SummaryWriter(output_dir / 'tensorboard')
        
        # Training loop
        logger.info("ðŸŽ¯ Starting training with balanced losses...")
        
        best_metric = 0.0
        
        for epoch in range(args.epochs):
            logger.info(f"\nðŸ“… Epoch {epoch + 1}/{args.epochs}")
            
            # Training
            model.train()
            train_metrics = []
            
            for batch_idx, (videos, targets) in enumerate(train_loader):
                metrics = trainer.train_step(videos, targets)
                train_metrics.append(metrics)
                
                if (batch_idx + 1) % 50 == 0:
                    avg_loss = sum(m['loss'] for m in train_metrics[-50:]) / min(50, len(train_metrics))
                    logger.info(f"  Batch {batch_idx + 1}/{len(train_loader)}: Loss = {avg_loss:.4f}")
            
            # Validation
            logger.info("ðŸ”¬ Running validation...")
            val_results = trainer.evaluate(val_loader, compute_detailed_metrics=True)
            
            # Log metrics
            avg_train_loss = sum(m['loss'] for m in train_metrics) / len(train_metrics)
            val_loss = val_results['avg_loss']
            
            logger.info(f"ðŸ“Š Epoch {epoch + 1} Results:")
            logger.info(f"   Train Loss: {avg_train_loss:.4f}")
            logger.info(f"   Val Loss: {val_loss:.4f}")
            
            # Print detailed metrics if available
            if 'metrics_table' in val_results:
                logger.info("ðŸ“‹ Validation Metrics:")
                print(val_results['metrics_table'])
            
            # Save best model
            current_metric = val_results.get('overall_accuracy', 1.0 - val_loss)
            if current_metric > best_metric:
                best_metric = current_metric
                
                checkpoint = {
                    'epoch': epoch + 1,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
                    'best_metric': best_metric,
                    'config': config
                }
                
                torch.save(checkpoint, output_dir / 'best_model.pth')
                logger.info(f"ðŸ’¾ New best model saved! Metric: {best_metric:.4f}")
            
            # Step scheduler
            if scheduler:
                scheduler.step()
            
            # Tensorboard logging
            writer.add_scalar('Loss/Train', avg_train_loss, epoch)
            writer.add_scalar('Loss/Val', val_loss, epoch)
            writer.add_scalar('Metric/Best', best_metric, epoch)
        
        writer.close()
        logger.info("ðŸŽ‰ Training completed successfully!")
        
    except Exception as e:
        logger.error(f"ðŸ’¥ Training failed: {e}")
        raise


if __name__ == '__main__':
    main() 